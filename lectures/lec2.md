# ğŸ“ŒLecture 2 - Threat Modeling & Security Requirements


## ğŸ“ Slide 1 â€“ ğŸ§­ What Is Threat Modeling?

* ğŸ§  **Definition:** a **structured analysis** to find and prioritize **potential threats** to a system **before** or **during** design/changes, and to plan **mitigations** that reduce risk. ([OWASP Developer Guide][1])
* ğŸ—‚ï¸ **Typical outputs:** diagrams (e.g., **Data Flow Diagrams**), a **threat list**, mapped **mitigations**, and **risk notes** tied to backlog items. ([OWASP Developer Guide][1])
* ğŸ” **When:** at design time, during major refactors, before launches, and on a cadence (e.g., each significant feature/sprint). ([OWASP Developer Guide][1])
* ğŸ”— **Read more:** OWASP Developer Guide â€” Threat Modeling in practice. ([OWASP Developer Guide][1])

```mermaid
flowchart LR
  A[Define Scope] --> B[Model System & Data Flows]
  B --> C[Identify Threats]
  C --> D[Rate & Prioritize]
  D --> E[Plan Mitigations]
  E --> F[Track in Backlog]
  F -->|changes| A
```

---

## ğŸ“ Slide 2 â€“ ğŸ“ˆ Why It Matters (Outcomes & Fresh Stats)

* ğŸ“Š **Reality check:** the **Verizon DBIR 2025** analyzed **22,052 incidents** and **12,195 breaches**â€”the **largest** set to date. ([Verizon][2])
* ğŸ•³ï¸ **Initial access trend:** **exploitation of vulnerabilities** grew **34% year-over-year**, now **\~20%** of breachesâ€”underscoring the value of modeling â€œ**what can be exploited**.â€ ([IT Services][3])
* ğŸ¤– **AI risk angle (new in 2025):** **13%** of orgs reported breaches of **AI models/apps**; many lack adequate **AI access controls**â€”threat modeling helps surface these attack paths. ([IBM Newsroom][4])
* ğŸ’· **Value of automation:** In the **UK**, broad **AI/automation** in security **reduced breach costs by >Â£600k** compared to non-users. ([IBM UK Newsroom][5])
* ğŸ”— **Read more:** DBIR 2025; IBM **Cost of a Data Breach 2025** resources. ([Verizon][2], [IBM][6])

---

## ğŸ“ Slide 3 â€“ ğŸ·ï¸ Assets, Threats, Vulnerabilities, Risk (Clear Terms)

* ğŸ§© **Asset:** anything of value to protect (e.g., service, data, identity). *(Used across NIST risk guidance.)* ([NIST CSRC][7])
* âš ï¸ **Threat:** a circumstance/event with potential to **adversely impact** operations or individuals via an information system. ([NIST Publications][8])
* ğŸ•³ï¸ **Vulnerability:** a **weakness** that can be **exploited** by a threat; consider **predisposing conditions** too. ([NIST Publications][8])
* ğŸ“‰ **Risk:** a **function of likelihood and impact** for a threat exploiting a vulnerability (context matters). ([NIST Publications][9])
* ğŸ”— **Read more:** NIST **SP 800-30 Rev.1** (risk assessment foundations). ([NIST Publications][8])

```mermaid
mindmap
  root((Risk))
    Asset("What we value")
    Threat("What can go wrong")
    Vulnerability("Why it could succeed")
    Impact("How bad if it happens")
    Likelihood("How probable")
```

---

## ğŸ“ Slide 4 â€“ ğŸ§± Trust Boundaries & ğŸ” Data Sensitivity

* ğŸ§­ **Trust boundary:** where **privilege/identity/zone** changes (e.g., Internet â†’ app tier, app â†’ database); crossing it increases **threat exposure**. ([OWASP Developer Guide][1])
* ğŸ—ƒï¸ **Classify data** (e.g., **PII**) to set impact expectations; NIST **SP 800-122** details **PII confidentiality impact levels** (low/moderate/high) and safeguards. ([NIST Publications][10])
* ğŸ§¾ **Document assumptions** (e.g., â€œDB is private network onlyâ€) and verify themâ€”assumptions are often where attacks land. ([OWASP Developer Guide][1])
* ğŸ”— **Read more:** OWASP Threat Modeling guidance; NIST **SP 800-122** (PII). ([OWASP Developer Guide][1], [NIST CSRC][11])

```mermaid
flowchart LR
  U[User] -->|HTTPS| W[Web/API]
  W -->|SvcAcct| A[App]
  A -->|SQL| D[(DB)]
  %% Trust boundaries:
  subgraph Internet Zone
    U
  end
  subgraph Corp Zone
    W
    A
  end
  subgraph Data Zone
    D
  end
```

---

## ğŸ“ Slide 5 â€“ ğŸŒ Attack Surface 101 (What Expands It?)

* ğŸ›°ï¸ **Definition:** the **portion of resources accessible to an adversary**; complex enterprises make it hard to enumerate without structured segmentation/visibility. ([CISA][12])
* ğŸŒ **Common contributors:** **public-facing endpoints**, **exposed edge/IoT/OT devices**, **third-party SaaS/APIs**, **secrets** in repos, **shadow AI** features. ([CISA][13], [IBM Newsroom][4])
* ğŸ§© **Zero Trust microsegmentation** **reduces** attack surface and **limits lateral movement**; now explicit CISA guidance (2025). ([CISA][14])
* ğŸ”— **Read more:** CISA **Microsegmentation Guidance** (Part One), CISA **OT mitigations**. ([CISA][12])

```mermaid
graph TD
  subgraph External
    I[Internet]:::risk
  end
  subgraph Org
    S1[Public Web/API]:::risk
    S2[VPN/GW]:::risk
    S3[Partner SaaS]:::risk
    OT[OT/IoT Edge]:::risk
    INT[Internal Services]
  end
  I-->S1
  I-->S2
  I-->S3
  I-->OT
  classDef risk fill:#ffe,stroke:#f66,stroke-width:2px;
```

---

## ğŸ“ Slide 6 â€“ ğŸ” Where Threat Modeling Fits (SDLC & Agile)

* ğŸ§ª **Design/Build:** run modeling during **architecture & design**, and as part of **feature kickoff**; keep models updated as the design evolves. ([OWASP Developer Guide][1])
* ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Team roles:** product owner clarifies **business impact**, engineers map **flows & boundaries**, security helps **enumerate threats**, everyone owns **mitigations**. ([OWASP Developer Guide][1])
* âœ… **Definition of Done:** mitigations **linked to backlog tickets**, controls **verified**, and **residual risk** captured/reviewed. ([Microsoft GitHub][15])
* ğŸ”— **Read more:** Microsoft **Engineering Playbook** (Threat Modelling), OWASP Developer Guide. ([Microsoft GitHub][15], [OWASP Developer Guide][1])

```mermaid
flowchart LR
  PB[Backlog] --> D[Design]
  D --> TM[Threat Model]
  TM --> M[Mitigations in Backlog]
  M --> Dev[Implement]
  Dev --> Test[Verify]
  Test --> PB
  %% Sprint-friendly loop with traceability
```

---

## ğŸ“ Slide 7 â€“ ğŸ—ºï¸ Data Flow Diagrams (DFDs) Essentials

* ğŸ§© **Why DFDs?** â€” They give a **visual map** of components, data stores, external entities, and flows; perfect for threat enumeration.
* ğŸ–¼ï¸ **Core elements:**

  * ğŸ“¦ **Processes** (rectangles)
  * ğŸ—„ï¸ **Data Stores** (cylinders)
  * ğŸŒ **External Entities** (actors, clouds)
  * ğŸ”€ **Data Flows** (arrows)
* ğŸ›‘ **Common pitfalls:** skipping external entities, over-complicated diagrams, not marking **trust boundaries**.
* ğŸ”— **Docs:** OWASP Threat Modeling Cheat Sheet.

```mermaid
flowchart LR
  User((User)) -->|HTTPS| Web[Web App]
  Web -->|SQL| DB[(Database)]
  Web --> API[Auth Service]
  API -->|Token| Web
  %% Trust boundary between User and Web
```

---

## ğŸ“ Slide 8 â€“ ğŸ§­ Scoping & Assumptions

* ğŸ“Œ **Define boundaries** â€” which systems **in/out of scope**; makes models actionable.
* ğŸ§¾ **Assumptions** â€” document them (e.g., â€œS3 bucket is privateâ€), then **challenge & test** later.
* ğŸ“‚ **Levels of trust:** assign zones (e.g., **public**, **internal**, **restricted**, **sensitive**).
* ğŸ› ï¸ **Practical tip:** start **small** (one feature/system), then grow. Donâ€™t boil the ocean.
* ğŸ”— **Docs:** OWASP Threat Dragon â€œGetting Startedâ€ guide.

```yaml
# Example: backlog entry for assumptions
threat_model_scope:
  in_scope:
    - "Customer web portal"
    - "Auth microservice"
  out_of_scope:
    - "Legacy CRM"
  assumptions:
    - "DB encrypted at rest"
    - "Internal network cannot be spoofed"
```

---

## ğŸ“ Slide 9 â€“ ğŸ§© STRIDE Framework Intro

* ğŸ§­ **Created by Microsoft** (1999) to classify threats in **six categories**, each tied to a **security property**.
* ğŸ”’ **Spoofing â†’ Authentication**
* ğŸ§ª **Tampering â†’ Integrity**
* ğŸ“‘ **Repudiation â†’ Non-repudiation**
* ğŸ” **Information Disclosure â†’ Confidentiality**
* ğŸ›‘ **Denial of Service â†’ Availability**
* ğŸ§° **Elevation of Privilege â†’ Authorization**
* ğŸ”— **Docs:** Microsoft Threat Modeling Tool (supports STRIDE).

```mermaid
mindmap
  root((STRIDE))
    S[Spoofing -> AuthN]
    T[Tampering -> Integrity]
    R[Repudiation -> Non-rep]
    I[Info Disclosure -> Confidentiality]
    D[Denial of Service -> Availability]
    E[EoP -> Authorization]
```

---

## ğŸ“ Slide 10 â€“ ğŸªª S = Spoofing

* ğŸ§© **Definition:** Pretending to be someone/something else to gain unauthorized access.
* ğŸ“Š **Examples:** credential stuffing, forged JWTs, fake service endpoints.
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸ”‘ Strong authentication (MFA, FIDO2, mTLS)
  * ğŸ—ï¸ Secure credential storage & rotation
  * ğŸ” Identity federation w/ auditing
* ğŸ“ˆ **Why it matters:** 2025 DBIR shows **credentials still top vector**, with attacks doubling vs 2024.
* ğŸ”— **Docs:** Microsoft SDL guidance, OWASP ASVS (auth controls).

```yaml
# Example: backlog security requirement
requirement:
  id: "AUTH-01"
  text: "All external endpoints MUST enforce MFA via OIDC provider."
  mapped_to: STRIDE:Spoofing
```

---

## ğŸ“ Slide 11 â€“ ğŸ§ª T = Tampering

* ğŸ§© **Definition:** Malicious **modification of data or code**.
* ğŸ“Š **Examples:** parameter tampering (price=0), code injection, log/file alteration.
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸ§° Input validation & canonicalization
  * ğŸ” Signatures & checksums on critical data
  * ğŸ”’ Integrity controls in pipelines (e.g., SLSA, Sigstore)
* ğŸ“ˆ **Why it matters:** Supply chain attacks grew **20% in 2025** (DBIR). Tampering is a key vector in dependency abuse.
* ğŸ”— **Docs:** Microsoft SDL, OWASP ASVS (data integrity).

```mermaid
flowchart LR
  U[User] --> W[Web App]
  W --> D[(DB)]
  W -.alter.-> D
  %% Tampering risk at boundary between W and D
```

---

## ğŸ“ Slide 12 â€“ ğŸ§¾ STRIDE Letters in Practice (Setup)

* ğŸ§¾ Weâ€™ve covered **S (Spoofing)** & **T (Tampering)** with examples and mitigations.
* ğŸ“‘ Next up: **R (Repudiation)**, **I (Information Disclosure)**, **D (Denial of Service)**, **E (Elevation of Privilege)**.
* ğŸ§° Each will get **its own slide** with **examples, mitigations, and use cases**.
* ğŸ› ï¸ This detail is critical: new students must see how **each STRIDE letter ties to concrete controls**.

---

## ğŸ“ Slide 13 â€“ ğŸ§¾ R = Repudiation

* ğŸ§© **Definition:** A user or system **denies performing an action** without supporting evidence available.
* ğŸ“Š **Examples:**

  * User disputes a financial transaction
  * Attacker deletes logs to cover tracks
  * Cloud API call without signed evidence
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸ“ **Audit logs** with **time sync** (NTP/chrony)
  * ğŸ” **Cryptographically signed logs** (e.g., append-only ledgers, immutability in cloud)
  * ğŸ•µï¸ **Monitoring & alerting** for tampered/erased events
* ğŸ“ˆ **Why it matters:** Legal & compliance investigations depend on reliable logs.
* ğŸ”— **Docs:** Microsoft SDL (repudiation mitigations), OWASP Logging Cheat Sheet.

```yaml
# Example log config snippet
logging:
  format: json
  integrity: signed
  retention_days: 365
  clock_sync: true
```

---

## ğŸ“ Slide 14 â€“ ğŸ” I = Information Disclosure

* ğŸ§© **Definition:** Exposure of **sensitive data** to unauthorized parties.
* ğŸ“Š **Examples:**

  * PII in verbose error messages
  * Leaky S3 bucket / misconfigured storage
  * Secrets in GitHub repos
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸ”’ Encryption in transit (TLS 1.2+/1.3) & at rest (AES-256, KMS)
  * ğŸ”‘ Secrets management (Vault, AWS Secrets Manager)
  * ğŸ§¹ Data minimization & masking in logs
* ğŸ“ˆ **Why it matters:** IBM 2025 report â€” **82% of breaches involved data stored in cloud**; misconfig remains a top driver.
* ğŸ”— **Docs:** OWASP ASVS (crypto requirements).

```mermaid
flowchart TD
  U[User] --> W[Web App]
  W -->|PII| DB[(Database)]
  DB -.misconfig.-> Public((World))
  %% Risk: Info Disclosure if DB exposed
```

---

## ğŸ“ Slide 15 â€“ ğŸ›‘ D = Denial of Service (DoS)

* ğŸ§© **Definition:** Attacks aiming to **degrade availability** of a system.
* ğŸ“Š **Examples:**

  * Volumetric floods (UDP amplification)
  * Logical DoS (regex bombs, algorithmic complexity)
  * Resource exhaustion (unbounded queue)
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸŒ Web Application Firewalls (WAF) + DDoS protection (CDN, scrubbing centers)
  * â±ï¸ Rate limits, back-pressure, exponential backoff
  * ğŸ”„ Circuit breakers in service-to-service calls
* ğŸ“ˆ **Why it matters:** 2025 DBIR shows **DoS still \~30% of incidents**, especially in finance & gov.
* ğŸ”— **Docs:** Microsoft SDL availability guidelines.

```yaml
# Example API rate-limit config
rate_limits:
  /login:
    rps: 5
    burst: 10
  /orders:
    rps: 50
```

---

## ğŸ“ Slide 16 â€“ ğŸ§° E = Elevation of Privilege (EoP)

* ğŸ§© **Definition:** Gaining **permissions** beyond what was intended.
* ğŸ“Š **Examples:**

  * User escalates from **reader â†’ admin** via IDOR
  * Privileged container escape
  * Default creds in cloud services
* ğŸ›¡ï¸ **Mitigations:**

  * ğŸ” Least privilege (RBAC/ABAC, Just-In-Time access)
  * ğŸ›¡ï¸ Defense in depth (network + app + OS controls)
  * ğŸ§¾ Security testing (IAST/DAST fuzzing for access control)
* ğŸ“ˆ **Why it matters:** EoP is **core to ransomware ops** â€” attackers escalate to deploy payloads org-wide.
* ğŸ”— **Docs:** Microsoft SDL (authorization), OWASP ASVS access control.

```mermaid
flowchart LR
  U[User: Reader] --> App
  App --> DB
  U--IDOR-->DB
  %% Risk: user bypasses control to gain EoP
```

---

## ğŸ“ Slide 17 â€“ ğŸ•µï¸â€â™€ï¸ LINDDUN Overview

* ğŸ§­ **What it is:** A **privacy threat modeling framework** created by KU Leuven; focuses on **privacy harms** instead of only security flaws.
* ğŸ§© **Acronym:** **L-I-N-D-D-U-N** â†’ Linkability, Identifiability, Non-repudiation, Detectability, Data Disclosure, Unawareness, Non-compliance.
* ğŸ§° **Purpose:** Helps identify **privacy risks** early in design (e.g., GDPR, HIPAA alignment).
* ğŸ§‘â€âš–ï¸ **Recognition:** Listed by **NIST Privacy Framework** as a key methodology (last updated March 2025).
* ğŸ”— **Docs:** [linddun.org](https://linddun.org/) | [NIST Privacy Framework LINDDUN page](https://www.nist.gov/privacy-framework/linddun-privacy-threat-modeling-framework)

```mermaid
flowchart TD
  U[User with PII] --> S[(System)]
  S --> A[Analytics]
  S --> L[Logs]
  %% Privacy issues:
  %% Linkability at A
  %% Data Disclosure at L
  %% Detectability from network metadata
```

---

## ğŸ“ Slide 18 â€“ ğŸ“š LINDDUN Methods & Aids

* ğŸ“‚ **Threat Catalogs & Trees:** Provide structured ways to brainstorm privacy issues for each LINDDUN category.
* ğŸƒ **LINDDUN GO cards:** Lightweight cards for quick workshops; each card = threat + countermeasure.
* ğŸ§° **Flavors:**

  * **LINDDUN GO (lightweight)** â†’ brainstorming in agile sprints.
  * **LINDDUN Pro** â†’ full threat tree + PET mapping.
  * **LINDDUN Maestro** â†’ large-scale system modeling, supported by tooling.
* ğŸ§ª **Outputs:** Identified threats â†’ mapped to **privacy-enhancing technologies (PETs)** like anonymization, pseudonymization, consent mgmt.
* ğŸ”— **Docs:** LINDDUN GO & Pro guidelines on [linddun.org](https://linddun.org/)

---

## ğŸ“ Slide 19 â€“ ğŸ§ª LINDDUN Use Cases

* ğŸŒ **Web analytics/advertising:** Detect **linkability/identifiability** risks; mitigate via pseudonyms, aggregation.
* ğŸ“± **Mobile health app:** **Detectability & Non-compliance** â€” traffic patterns reveal sensitive use; mitigated by encryption, DPIAs.
* ğŸ  **IoT devices (smart home):** **Unawareness** of telemetry collection; add explicit consent & notice.
* ğŸ§© **Integration:** Often run **alongside STRIDE** for full picture (security + privacy).
* ğŸ“Š **Industry uptake:** Increasingly adopted in **DPIA processes** across EU-based companies (per NIST & LINDDUN Foundation guidance, 2025).

---

## ğŸ“ Slide 20 â€“ ğŸ›ï¸ PASTA Overview

* ğŸ§­ **What it is:** **Process for Attack Simulation & Threat Analysis (PASTA)** â€” a **7-stage, risk-centric methodology**.
* ğŸ“‘ **Goal:** Align **business objectives** with **technical threats** â†’ ensure risks have measurable business impact.
* ğŸ”„ **Approach:** Iterative and **attacker-centric**, simulating how adversaries would exploit systems.
* ğŸ§° **Inventors:** Developed by **VerSprite**; widely used in enterprises needing regulatory alignment (finance, healthcare).
* ğŸ”— **Docs:** [VerSprite PASTA Threat Modeling](https://versprite.com/blog/pasta-threat-modeling-solution/)

```mermaid
flowchart LR
  A[Business Objectives] --> B[Technical Decomposition]
  B --> C[Threat Identification]
  C --> D[Vulnerability Analysis]
  D --> E[Attack Simulation]
  E --> F[Risk & Impact]
  F --> G[Controls & Validation]
```

---

## ğŸ“ Slide 21 â€“ ğŸ§ª PASTA 7 Stages in Detail

1. **Define Business Objectives** â€” scope, business drivers, compliance targets.
2. **Define Technical Scope** â€” decompose app/system, map trust boundaries.
3. **Application Decomposition & Threat Analysis** â€” identify threats/abuse cases.
4. **Vulnerability Analysis** â€” discover flaws (manual, automated).
5. **Attack Simulation** â€” model adversary behavior & kill chains.
6. **Risk & Impact Analysis** â€” map technical to **business risk**.
7. **Controls & Mitigations** â€” define countermeasures, test, and validate.

* ğŸ§¾ **Outputs:** Risk register with business impact traceability; prioritized mitigations.
* ğŸ—ï¸ **Strength:** Ensures executives, architects, and testers all speak the **same risk language**.&#x20;

---

## ğŸ“ Slide 22 â€“ ğŸ“Š PASTA Case Study

* ğŸ¦ **Scenario:** Online banking app in EU.
* ğŸ” **Stage 1:** Objective â†’ protect financial data & comply with PSD2.
* ğŸ” **Stage 3â€“4:** Identified threats â†’ credential stuffing, replay, insecure APIs; vulnerabilities in session handling.
* ğŸ­ **Stage 5:** Attack simulation showed chaining replay + weak session validation â†’ account takeover.
* ğŸ“Š **Stage 6:** Business impact = customer fraud losses, regulatory fines.
* ğŸ§° **Stage 7:** Mitigations = MFA, replay protection, secure session mgmt.
* ğŸ“ˆ **Benefit:** Board-level risk visibility (â€œâ‚¬ loss if attack succeedsâ€) â†’ prioritized MFA rollout across all channels.

---

## ğŸ“ Slide 23 â€“ ğŸš€ VAST Overview

* ğŸ§­ **What it is:** **Visual, Agile, and Simple Threat (VAST)** modeling â€” a framework designed for **enterprise-scale adoption**.
* ğŸ§° **Created by:** **ThreatModeler** to address scalability problems in traditional threat modeling approaches.
* âš™ï¸ **Core idea:** Threat modeling must be **automated, continuous, and aligned with Agile/DevOps** practices.
* ğŸ¢ **Why VAST matters:**

  * Scales across **hundreds of applications**.
  * Keeps modeling accessible to **developers and non-security roles**.
  * Produces consistent, organization-wide threat intelligence.
* ğŸ”— **Docs:** [ThreatModeler VAST Overview](https://threatmodeler.com/innovation-lab/vast/)&#x20;

```mermaid
flowchart TB
  Dev[Developer Team] -->|Stories| Backlog
  Sec[Security Team] -->|Threat Patterns| Backlog
  Ops[Operations] -->|Infra Risks| Backlog
  Backlog --> VAST[VAST Modeling]
  VAST --> Report[Threat Reports + Mitigations]
```

---

## ğŸ“ Slide 24 â€“ ğŸ”Œ VAST Integrations & Use Cases

* ğŸ”„ **Application Threat Models:** Auto-generate threat models from architecture diagrams, cloud templates, or CI/CD pipelines.
* ğŸ—ï¸ **Operational Threat Models:** Extend modeling to **infrastructure & deployment** (e.g., Kubernetes, AWS).
* ğŸš€ **Integration:** Embeds directly into **Agile backlog tools** (Jira, Azure DevOps) â†’ devs see threats as **user stories**.
* ğŸ“Š **Use Cases:**

  * Large enterprises needing **consistent risk coverage**.
  * Organizations adopting **DevOps at scale**.
  * Continuous compliance for **PCI, HIPAA, NIST 800-53**.
* ğŸ“ˆ **Industry trend (2025):** ThreatModeler reports enterprises using VAST can reduce **manual modeling time by \~60%** across portfolios (per vendor benchmarks).

---

## ğŸ“ Slide 25 â€“ ğŸ’¹ FAIR Overview

* ğŸ§­ **What it is:** **FAIR = Factor Analysis of Information Risk** â€” the **international standard (Open FAIR)** for **quantitative risk analysis**.
* ğŸ’µ **Goal:** Express cyber risk in **financial terms** (probable loss, ranges, confidence levels) instead of vague â€œhigh/medium/low.â€
* ğŸ§© **Core factors:**

  * **Loss Event Frequency (LEF)** = Threat Event Frequency Ã— Vulnerability.
  * **Loss Magnitude (LM)** = Primary + Secondary losses (direct + indirect impacts).
* ğŸ§° **Use cases:**

  * Prioritize mitigations by **expected \$ impact**.
  * Communicate risk to **executives and boards**.
  * Compare control ROI across projects.
* ğŸ”— **Docs:** [FAIR Institute â€“ What is FAIR?](https://www.fairinstitute.org/what-is-fair) (updated 2025)

```mermaid
flowchart LR
  Threat[Threat Event] -->|Frequency| LEF[Loss Event Frequency]
  LEF --> Risk[$ Risk Estimate]
  Vuln[Vulnerability] --> LEF
  Risk --> LM[Loss Magnitude]
  LM --> Report[Business Impact Report]
```

---

## ğŸ“ Slide 26 â€“ ğŸ§® FAIR in Practice

* ğŸ¦ **Example:** Bank analyzing risk of API credential stuffing.

  * **LEF:** 12 times/year (based on incident data).
  * **Vulnerability:** Moderate (API lacks strict lockout).
  * **Loss Magnitude:**

    * **Primary:** Fraud reimbursements = \$5M/yr.
    * **Secondary:** Regulator fines, reputation damage = \$10M/yr.
  * **Total risk:** \~\$15M/year.
* ğŸ“Š **Result:** Clear **business case** for investing \$2M in stronger authn controls + fraud monitoring.
* ğŸ“ˆ **Industry adoption:** By 2025, FAIR is used by >50% of Fortune 100 companies for **cyber risk quantification** (FAIR Institute).
* ğŸ¤ **Pairing:** Works well when combined with **STRIDE/PASTA/VAST** â†’ identify threats, then quantify impact with FAIR.

---

## ğŸ“ Slide 27 â€“ ğŸ§± Threagile Overview

* ğŸ§­ **What it is:** **Threagile** is an **open-source Agile Threat Modeling Toolkit** (by Christian Schneider).
* ğŸ“œ **Concept:** Treats **threat models as code** â†’ written in **YAML** files, versioned in Git, integrated into DevOps.
* ğŸ§° **Outputs:**

  * ğŸ“Š Risk reports (JSON/XLSX/PDF).
  * ğŸ—ºï¸ Auto-generated **Data Flow Diagrams (DFDs)**.
  * âš ï¸ Risk rules engine â†’ finds issues like unencrypted traffic, missing authn.
* ğŸ“ˆ **Benefits:**

  * Agile-friendly (works in sprints).
  * Automatable (CLI, Docker, REST).
  * Repeatable (models live with code).
* ğŸ”— **Docs:** [threagile.io](https://threagile.io/) | [About Threagile](https://threagile.io/about/index.html)&#x20;

```yaml
# ğŸ“‚ Example: Threagile YAML model (simplified)
title: Online Shop
technical_assets:
  webapp:
    type: web-application
    communication_links:
      - target: database
        protocol: https
```

---

## ğŸ“ Slide 28 â€“ ğŸ§° Threagile Workflow & Use Cases

* ğŸ”„ **Workflow:**

  1. Define model in **YAML** (assets, comms, data).
  2. Run `threagile` CLI â†’ generates **DFD + risk report**.
  3. Export to **JSON/XLSX** â†’ feed into risk mgmt systems.
  4. Track risks like backlog items in Agile boards.
* ğŸ§ª **Use Cases:**

  * **Microservices architecture** â†’ model each service, see inter-service risks.
  * **Cloud migration** â†’ identify new attack surfaces (S3 buckets, APIs).
  * **Regulated systems** â†’ auto-generate reports for auditors.
* ğŸ“Š **Advanced metrics:** **Relative Attacker Attractiveness (RAA)** & **Data Loss Probability (DLP)** quantify risk importance. (DEF CON talk, widely adopted 2024â€“2025).
* ğŸ¤ **Integration:** Works with IDEs, GitHub Actions, GitLab CI.
* ğŸ“ˆ **Trend:** By 2025, Threagile is used in many **â€œshift-leftâ€ security pipelines** as the de facto â€œcode-firstâ€ modeling approach.

---

## ğŸ“ Slide 29 â€“ ğŸ‰ OWASP Threat Dragon Overview

* ğŸ§­ **What it is:** **Threat Dragon** is an **open-source threat modeling tool** from **OWASP**.
* ğŸ–¥ï¸ **Versions:**

  * **Desktop app** (Win/Mac/Linux).
  * **Web app** (hosted or self-hosted).
* ğŸ§° **Features (v2.x, 2024â€“2025 releases):**

  * Supports **multiple methodologies**: STRIDE, LINDDUN, CIA, DIE, PLOT4ai.
  * **Rule engine** â†’ auto-suggests threats based on diagram context.
  * Export models in **JSON**.
  * Integration with **GitHub/GitLab repos**.
* ğŸ“Š **Focus:** Make threat modeling accessible for dev teams (friendly UI, drag-and-drop).
* ğŸ”— **Docs:** [OWASP Threat Dragon Project Page](https://owasp.org/www-project-threat-dragon/)&#x20;

```json
{
  "summary": "Sample Threat Model",
  "threats": [
    { "id": "T1", "title": "SQL Injection", "method": "STRIDE-Tampering" },
    { "id": "T2", "title": "Data Exposure", "method": "LINDDUN-Disclosure" }
  ]
}
```

---

## ğŸ“ Slide 30 â€“ ğŸ§ª Threat Dragon Workflow & Use Cases

* ğŸ”„ **Workflow:**

  1. Create a **Data Flow Diagram** (DFD) â†’ processes, stores, flows, externals.
  2. Tool auto-suggests **candidate threats**.
  3. Team reviews, accepts, or refines threats.
  4. Export model as **JSON** â†’ track in repo or issue tracker.
* ğŸ§ª **Use Cases:**

  * Agile teams doing lightweight threat modeling inside sprints.
  * Privacy/security workshops (with STRIDE + LINDDUN side by side).
  * Teaching & training (used in many university AppSec courses).
* ğŸ“ˆ **Trend (2025):** Maintainers report growing adoption due to **integration with DevOps workflows** and support for **AI-related threat patterns (PLOT4ai)** in latest versions.&#x20;
* ğŸ¤ **Comparison:**

  * **Threagile** â†’ code-centric, automation-first.
  * **Threat Dragon** â†’ diagram-centric, collaboration-first.
  * Both complement each other in different DevSecOps contexts.

---

[1]: https://devguide.owasp.org/en/04-design/01-threat-modeling/01-threat-modeling/ "Threat modeling in practice - OWASP Developer Guide"
[2]: https://www.verizon.com/business/resources/T163/reports/2025-dbir-data-breach-investigations-report.pdf "2025 Data Breach Investigations Report - Verizon"
[3]: https://its.ny.gov/system/files/documents/2025/06/maguire-verizon.pdf "2025 Data Breach Investigations Report - its.ny.gov"
[4]: https://newsroom.ibm.com/2025-07-30-ibm-report-13-of-organizations-reported-breaches-of-ai-models-or-applications%2C-97-of-which-reported-lacking-proper-ai-access-controls "IBM Report: 13% Of Organizations Reported Breaches Of AI Models Or ..."
[5]: https://uk.newsroom.ibm.com/2025-cost-of-data-breach-UK?asPDF=1&utm_source=chatgpt.com "IBM Report: UK Sees Drop in Breach Costs as AI Speeds Detection"
[6]: https://www.ibm.com/think/x-force/2025-cost-of-a-data-breach-navigating-ai "2025 Cost of a Data Breach Report: Navigating the AI rush without ... - IBM"
[7]: https://csrc.nist.gov/pubs/sp/800/30/r1/final "SP 800-30 Rev. 1, Guide for Conducting Risk Assessments | CSRC"
[8]: https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-30r1.pdf "NIST Special Publication 800-30 Revision 1, Guide for Conducting Risk ..."
[9]: https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-30.pdf "Archived NIST Technical Series Publication"
[10]: https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-122.pdf "NIST SP 800-122, Guide to Protecting the Confidentiality of Personally ..."
[11]: https://csrc.nist.gov/pubs/sp/800/122/final "SP 800-122, Guide to Protecting the Confidentiality of Personally ..."
[12]: https://www.cisa.gov/sites/default/files/2025-07/ZT-Microsegmentation-Guidance-Part-One_508c.pdf "The Journey to Zero Trust: Microsegmentation in Zero Trust Part ... - CISA"
[13]: https://www.cisa.gov/resources-tools/resources/primary-mitigations-reduce-cyber-threats-operational-technology "Primary Mitigations to Reduce Cyber Threats to Operational ... - CISA"
[14]: https://www.cisa.gov/news-events/alerts/2025/07/29/cisa-releases-part-one-zero-trust-microsegmentation-guidance "CISA Releases Part One of Zero Trust Microsegmentation Guidance"
[15]: https://microsoft.github.io/code-with-engineering-playbook/security/threat-modelling/ "Threat Modeling - Engineering Fundamentals Playbook"
